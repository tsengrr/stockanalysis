import os
import json
import feedparser
import yfinance as yf
import pandas as pd
from textblob import TextBlob
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from datetime import datetime
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from ta.momentum import RSIIndicator
from ta.trend import SMAIndicator
import plotly.graph_objects as go
from flask import Flask, render_template_string, request
import numpy as np

# å¤šéš»è‚¡ç¥¨åˆ†æ
tickers = ["NVDA", "AAPL", "MSFT", "GOOGL", "TSLA", "AMZN", "META"]
print(f"åˆ†æè‚¡ç¥¨: {', '.join(tickers)}")

end_date = datetime.today().strftime('%Y-%m-%d')

# å„²å­˜æ‰€æœ‰è‚¡ç¥¨çš„çµæœ
all_results = {}

# é€šç”¨æ–°èæƒ…ç·’åˆ†æå‡½æ•¸
def get_weighted_sentiment(ticker):
    # é‡å°ä¸åŒè‚¡ç¥¨çš„RSSä¾†æº
    rss_sources = [
        f"https://news.google.com/rss/search?q={ticker}",
        f"https://feeds.finance.yahoo.com/rss/2.0/headline?s={ticker}&region=US&lang=en-US",
        f"https://feeds.marketwatch.com/marketwatch/StockPulse?symbol={ticker}",
        f"https://news.google.com/rss/search?q={ticker}+stock",
        "https://feeds.a.dj.com/rss/RSSMarketsMain.xml"  # Dow Jones
    ]
    
    all_articles = []
    
    # é‡è¦æ€§é—œéµå­—æ¬Šé‡
    importance_keywords = {
        'earnings': 3.0,
        'revenue': 2.5,
        'profit': 2.5,
        'guidance': 2.5,
        'AI': 2.0,
        'datacenter': 2.0,
        'gaming': 1.5,
        'chip': 1.5,
        'semiconductor': 1.5,
        'acquisition': 2.0,
        'partnership': 1.5,
        'breakthrough': 2.0,
        'crisis': 2.0,
        'lawsuit': 1.8,
        'regulation': 1.8
    }
    
    for rss_url in rss_sources:
        try:
            print(f"  Fetching {ticker} news from: {rss_url}")
            feed = feedparser.parse(rss_url)
            
            for entry in feed.entries:
                if 'link' in entry:
                    try:
                        title = entry.title.lower()
                        # ç¢ºä¿æ–°èèˆ‡è©²è‚¡ç¥¨ç›¸é—œ
                        if ticker.lower() in title or any(keyword in title for keyword in [ticker.lower(), 'stock', 'market']):
                            analysis = TextBlob(entry.title)
                            sentiment_score = analysis.sentiment.polarity
                            
                            # æ ¹æ“šé—œéµå­—è¨ˆç®—é‡è¦æ€§æ¬Šé‡
                            importance_weight = 1.0
                            for keyword, weight in importance_keywords.items():
                                if keyword in title:
                                    importance_weight = max(importance_weight, weight)
                            
                            # è§£ææ—¥æœŸ
                            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                date = datetime(*entry.published_parsed[:6])
                            else:
                                date = datetime.now()
                            
                            weighted_sentiment = sentiment_score * importance_weight
                            
                            all_articles.append({
                                "date": date,
                                "sentiment": sentiment_score,
                                "weighted_sentiment": weighted_sentiment,
                                "importance_weight": importance_weight,
                                "title": entry.title,
                                "source": rss_url
                            })
                            
                    except Exception as e:
                        continue
                        
        except Exception as e:
            print(f"  Error fetching from {rss_url}: {e}")
            continue
    
    return all_articles

# åˆ†ææ¯éš»è‚¡ç¥¨
for ticker in tickers:
    print(f"\n{'='*50}")
    print(f"åˆ†æè‚¡ç¥¨: {ticker}")
    print(f"{'='*50}")
    
    try:
        # ä¸‹è¼‰è‚¡ç¥¨è³‡æ–™
        stock_data = yf.download(ticker, start="2020-01-01", end=end_date)
        
        # è™•ç†å¤šå±¤æ¬„ä½åç¨±
        if stock_data.columns.nlevels > 1:
            stock_data.columns = stock_data.columns.get_level_values(0)
        
        # ç¢ºä¿Closeè³‡æ–™æ˜¯ä¸€ç¶­çš„
        close_series = stock_data['Close'].squeeze()
        
        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
        stock_data['MA_5'] = SMAIndicator(close=close_series, window=5).sma_indicator()
        stock_data['MA_20'] = SMAIndicator(close=close_series, window=20).sma_indicator()
        stock_data['RSI'] = RSIIndicator(close=close_series, window=14).rsi()
        
        #  å°‡æŠ€è¡“æŒ‡æ¨™å»¶é²1å¤©
        stock_data['MA_5_lag'] = stock_data['MA_5'].shift(1)
        stock_data['MA_20_lag'] = stock_data['MA_20'].shift(1)
        stock_data['RSI_lag'] = stock_data['RSI'].shift(1)
        stock_data['Volume_lag'] = stock_data['Volume'].shift(1)
        
        stock_data = stock_data.bfill()
        
        # ç²å–è©²è‚¡ç¥¨çš„æƒ…ç·’åˆ†æ
        print(f"Fetching news sentiment data for {ticker}...")
        articles = get_weighted_sentiment(ticker)
        print(f"Total articles collected for {ticker}: {len(articles)}")
        
        if articles:
            articles_df = pd.DataFrame(articles)
            articles_df.set_index('date', inplace=True)
            
            # æ¯æ—¥æƒ…ç·’å½™ç¸½
            articles_daily = articles_df.groupby(articles_df.index.date).agg({
                'sentiment': 'mean',
                'weighted_sentiment': 'mean',
                'importance_weight': 'mean'
            })
            
            articles_daily['final_sentiment'] = articles_daily['weighted_sentiment']
            
        else:
            print(f"No articles found for {ticker}, using dummy sentiment data")
            articles_daily = pd.DataFrame({
                'final_sentiment': [0.0] * len(stock_data)
            }, index=stock_data.index)
        
        # æ¨™æº–åŒ–æƒ…ç·’åˆ†æ•¸
        scaler = StandardScaler()
        if len(articles_daily) > 0:
            articles_daily['final_sentiment'] = scaler.fit_transform(articles_daily[['final_sentiment']])
        
        # ä¿®æ­£ç´¢å¼•ä»¥ä¾¿åˆä½µ
        stock_data.index = pd.to_datetime(stock_data.index.date)
        articles_daily.index = pd.to_datetime(articles_daily.index)
        
        # å°‡æƒ…ç·’åˆ†æ•¸å»¶é²1å¤©ä»¥é¿å…è³‡æ–™æ´©æ¼
        articles_daily['sentiment_lag'] = articles_daily['final_sentiment'].shift(1)
        
        combined_df = stock_data.join(articles_daily[['sentiment_lag']], how='left')
        combined_df = combined_df.bfill()
        
        #  ä½¿ç”¨å»¶é²ç‰¹å¾µé¿å…è³‡æ–™æ´©æ¼
        X = combined_df[['sentiment_lag', 'Volume_lag', 'MA_5_lag', 'MA_20_lag', 'RSI_lag']]
        y = combined_df['Close']
        
        # ç§»é™¤åŒ…å«NaNçš„è¡Œ
        X = X.dropna()
        y = y[X.index]
        y = y.dropna()
        
        # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™
        if len(X) < 50:
            print(f"Warning: Limited data available for {ticker}")
            continue
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # è¨“ç·´æ¨¡å‹
        models = {
            'LinearRegression': LinearRegression(),
            'GradientBoosting': GradientBoostingRegressor(n_estimators=400, random_state=42),
            'DecisionTree': DecisionTreeRegressor(criterion='squared_error', max_depth=3, random_state=42),
            'RandomForest': RandomForestRegressor(criterion='squared_error', n_estimators=10, random_state=42, n_jobs=8)
        }
        
        model_results = {}
        
        for model_name, model in models.items():
            model.fit(X_train, y_train)
            train_score = model.score(X_train, y_train)
            test_score = model.score(X_test, y_test)
            print(f'{model_name} score (train): {train_score:.4f}')
            print(f'{model_name} score (test): {test_score:.4f}')
            
            model_results[model_name] = {
                'model': model,
                'train_score': train_score,
                'test_score': test_score
            }
        
        print(f"\n=== {ticker} åƒ¹æ ¼é æ¸¬ ===")
        
        # ç²å–æœ€æ–°è³‡æ–™é»çš„ç‰¹å¾µ
        latest_sentiment = float(articles_daily['sentiment_lag'].iloc[-1]) if len(articles_daily) > 0 and not pd.isna(articles_daily['sentiment_lag'].iloc[-1]) else 0.0
        latest_volume = float(stock_data['Volume_lag'].iloc[-1])
        latest_ma_5 = float(stock_data['MA_5_lag'].iloc[-1])
        latest_ma_20 = float(stock_data['MA_20_lag'].iloc[-1])
        latest_rsi = float(stock_data['RSI_lag'].iloc[-1])
        
        print(f"ä½¿ç”¨å‰ä¸€æ—¥ç‰¹å¾µ:")
        print(f"Sentiment: {latest_sentiment:.4f}")
        print(f"Volume: {latest_volume:,.0f}")
        print(f"MA_5: {latest_ma_5:.2f}")
        print(f"MA_20: {latest_ma_20:.2f}")
        print(f"RSI: {latest_rsi:.2f}")
        
        X_new = pd.DataFrame({
            'sentiment_lag': [latest_sentiment],
            'Volume_lag': [latest_volume],
            'MA_5_lag': [latest_ma_5],
            'MA_20_lag': [latest_ma_20],
            'RSI_lag': [latest_rsi]
        })
        
        # ç²å–ç•¶å‰å¯¦éš›åƒ¹æ ¼é€²è¡Œæ¯”è¼ƒ
        current_close = float(stock_data['Close'].iloc[-1])
        
        print(f"\nç•¶å‰æ”¶ç›¤åƒ¹: ${current_close:.2f}")
        
        predictions = {}
        for model_name, model_info in model_results.items():
            predicted_price = model_info['model'].predict(X_new)[0]
            change_percent = ((predicted_price - current_close) / current_close * 100)
            predictions[model_name] = {
                'predicted_price': predicted_price,
                'change_percent': change_percent
            }
            print(f"ä½¿ç”¨ {model_name} é æ¸¬åƒ¹æ ¼: ${predicted_price:.2f} ({change_percent:+.2f}%)")
        
        # å„²å­˜è©²è‚¡ç¥¨çš„çµæœ
        all_results[ticker] = {
            'current_price': current_close,
            'model_scores': model_results,
            'predictions': predictions,
            'latest_features': X_new.iloc[0].to_dict()
        }
        
    except Exception as e:
        print(f"Error processing {ticker}: {e}")
        continue

#  ç¸½çµæ‰€æœ‰è‚¡ç¥¨çš„é æ¸¬çµæœ
print(f"\n{'='*80}")
print("æ‰€æœ‰è‚¡ç¥¨é æ¸¬ç¸½çµ")
print(f"{'='*80}")

for ticker, results in all_results.items():
    print(f"\n{ticker} - ç•¶å‰åƒ¹æ ¼: ${results['current_price']:.2f}")
    print("-" * 50)
    
    # é¡¯ç¤ºæœ€ä½³æ¨¡å‹ï¼ˆåŸºæ–¼æ¸¬è©¦åˆ†æ•¸ï¼‰
    best_model = max(results['model_scores'].items(), key=lambda x: x[1]['test_score'])
    best_model_name = best_model[0]
    best_prediction = results['predictions'][best_model_name]
    
    print(f"æœ€ä½³æ¨¡å‹: {best_model_name} (æ¸¬è©¦åˆ†æ•¸: {best_model[1]['test_score']:.4f})")
    print(f"é æ¸¬åƒ¹æ ¼: ${best_prediction['predicted_price']:.2f}")
    print(f"é æœŸè®ŠåŒ–: {best_prediction['change_percent']:+.2f}%")
    
    # é¡¯ç¤ºæ‰€æœ‰æ¨¡å‹çš„å¹³å‡é æ¸¬
    avg_prediction = sum([pred['predicted_price'] for pred in results['predictions'].values()]) / len(results['predictions'])
    avg_change = ((avg_prediction - results['current_price']) / results['current_price'] * 100)
    print(f"å¹³å‡é æ¸¬: ${avg_prediction:.2f} ({avg_change:+.2f}%)")

print(f"\n{'='*80}")
print("åˆ†æå®Œæˆï¼")
print(f"{'='*80}")

# ------------------ å•Ÿå‹• Flask ä¼ºæœå™¨ ------------------
app = Flask(__name__)

# é æ¸¬æœªä¾† n å¤©åƒ¹æ ¼ï¼ˆé«˜æ•ˆç‡ï¼‰
def predict_n_days(stock_data, features_df, model, n_days=30):
    future_predictions = []
    current_features = features_df.iloc[-1].copy()

    for _ in range(n_days):
        X_input = pd.DataFrame([current_features])
        predicted_price = model.predict(X_input)[0]
        future_predictions.append(predicted_price)

        close_vals = list(features_df['MA_5_lag'].dropna().values[-4:]) + [predicted_price]
        current_features['MA_5_lag'] = np.mean(close_vals)

        close_vals = list(features_df['MA_20_lag'].dropna().values[-19:]) + [predicted_price]
        current_features['MA_20_lag'] = np.mean(close_vals)

        current_features['RSI_lag'] = min(max(current_features['RSI_lag'] + np.random.uniform(-1, 1), 0), 100)
        current_features['Volume_lag'] = current_features['Volume_lag']
        current_features['sentiment_lag'] = current_features['sentiment_lag']

    return future_predictions

# è¨“ç·´æ‰€æœ‰æ¨¡å‹ä¸¦è¿”å›
available_models = {
    'LinearRegression': LinearRegression(),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=300),
    'RandomForest': RandomForestRegressor(n_estimators=100),
    'DecisionTree': DecisionTreeRegressor(criterion='squared_error', max_depth=3, random_state=0)

}

# è¨“ç·´æ¨¡å‹ä¸¦å–å¾—ç‰¹å¾µèˆ‡é æ¸¬è³‡æ–™ï¼ˆå°è£ï¼‰
def analyze_stock(ticker):
    end_date = datetime.today().strftime('%Y-%m-%d')
    stock_data = yf.download(ticker, start="2020-01-01", end=end_date)
    if stock_data.columns.nlevels > 1:
        stock_data.columns = stock_data.columns.get_level_values(0)

    close_series = stock_data['Close'].squeeze()
    stock_data['MA_5'] = SMAIndicator(close=close_series, window=5).sma_indicator()
    stock_data['MA_20'] = SMAIndicator(close=close_series, window=20).sma_indicator()
    stock_data['RSI'] = RSIIndicator(close=close_series, window=14).rsi()
    stock_data['MA_5_lag'] = stock_data['MA_5'].shift(1)
    stock_data['MA_20_lag'] = stock_data['MA_20'].shift(1)
    stock_data['RSI_lag'] = stock_data['RSI'].shift(1)
    stock_data['Volume_lag'] = stock_data['Volume'].shift(1)
    stock_data = stock_data.bfill()

    stock_data['sentiment_lag'] = 0.0
    X = stock_data[['sentiment_lag', 'Volume_lag', 'MA_5_lag', 'MA_20_lag', 'RSI_lag']]
    y = stock_data['Close']
    X = X.dropna()
    y = y[X.index]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    models = {name: mdl.fit(X_train, y_train) for name, mdl in available_models.items()}
    return stock_data, X, models

@app.route('/', methods=['GET', 'POST'])
def index():
    chart_html = ""
    summary_html = ""
    error_msg = ""

    if request.method == 'POST':
        try:
            retrain = request.form.get('retrain', '') == '1'
            ticker = request.form.get('ticker', '').strip().upper()
            n_days = int(request.form.get('days', 30))
            model_choice = request.form.get('model', 'GradientBoosting')

            if not ticker:
                error_msg = "è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿã€‚"
            elif n_days <= 0:
                error_msg = "é æ¸¬å¤©æ•¸å¿…é ˆç‚ºæ­£æ•´æ•¸ã€‚"
            elif model_choice not in available_models:
                error_msg = "æ¨¡å‹é¸æ“‡ç„¡æ•ˆã€‚"
            else:
                model_path = f"cache/model_{ticker}_{model_choice}.pkl"
                feature_path = f"cache/X_latest_{ticker}.json"

                if retrain:
                    if os.path.exists(model_path):
                        os.remove(model_path)
                    if os.path.exists(feature_path):
                        os.remove(feature_path)

                stock_data, features_df, trained_models = analyze_stock(ticker)
                model = trained_models[model_choice]
                predicted_prices = predict_n_days(stock_data, features_df, model, n_days=n_days)

                current_price = stock_data['Close'].iloc[-1]
                mean_pred = np.mean(predicted_prices)
                std_pred = np.std(predicted_prices)

                past_prices = list(stock_data['Close'].iloc[-30:])
                full_series = past_prices + predicted_prices
                x_axis = list(range(1, len(full_series) + 1))

                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=x_axis[:30], y=past_prices,
                    mode='lines+markers', name='éå»30å¤©',
                    hovertemplate='å¤©æ•¸ %{x}<br>åƒ¹æ ¼: %{y:.2f}'
                ))
                fig.add_trace(go.Scatter(
                    x=x_axis[30:], y=predicted_prices,
                    mode='lines+markers', name='é æ¸¬åƒ¹æ ¼',
                    hovertemplate='å¤©æ•¸ %{x}<br>é æ¸¬: %{y:.2f}'
                ))
                fig.add_trace(go.Scatter(
                    x=x_axis[30:], y=[p + 1.96 * std_pred for p in predicted_prices],
                    mode='lines', name='95% ä¸Šé™', line=dict(dash='dot', color='lightblue'),
                    hovertemplate='å¤©æ•¸ %{x}<br>ä¸Šé™: %{y:.2f}'
                ))
                fig.add_trace(go.Scatter(
                    x=x_axis[30:], y=[p - 1.96 * std_pred for p in predicted_prices],
                    mode='lines', name='95% ä¸‹é™', line=dict(dash='dot', color='lightblue'),
                    hovertemplate='å¤©æ•¸ %{x}<br>ä¸‹é™: %{y:.2f}'
                ))
                fig.update_layout(
                    title=f"{ticker} éå»30å¤©èˆ‡æœªä¾†{n_days}å¤©é æ¸¬ï¼ˆå« 95% ä¿¡å¿ƒå€é–“ï¼‰ ({model_choice})",
                    xaxis_title="å¤©æ•¸ (1=æœ€èˆŠ, å…±{}å¤©)".format(len(full_series)),
                    yaxis_title="åƒ¹æ ¼ (USD)",
                    yaxis=dict(range=[min(full_series)-3, max(full_series)+3])
                )
                chart_html = fig.to_html(full_html=False)

                summary_html = f"""
                <h3>ğŸ“Œ çµ±è¨ˆæ‘˜è¦</h3>
                <ul>
                    <li>ä½¿ç”¨æ¨¡å‹ï¼š{model_choice}</li>
                    <li>æœ€æ–°ä¸€ç­†åƒ¹æ ¼ï¼š${current_price:.2f}</li>
                    <li>å¹³å‡é æ¸¬åƒ¹æ ¼ï¼š${mean_pred:.2f}</li>
                    <li>é æ¸¬è®ŠåŒ–ï¼š{((mean_pred - current_price) / current_price) * 100:+.2f}%</li>
                    <li>æ¨™æº–å·®ï¼šÂ±${std_pred:.2f}</li>
                </ul>
                """

        except ValueError:
            error_msg = "è«‹è¼¸å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£è™Ÿã€‚"
        except Exception as e:
            error_msg = f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"

    html_template = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>å‹•æ…‹è‚¡ç¥¨é æ¸¬å„€è¡¨æ¿</title>
        <style>
            body {{ font-family: sans-serif; background-color: #f8f9fa; padding: 30px; }}
            input, select, button {{ padding: 8px; margin: 5px; }}
            label {{ font-weight: bold; }}
            .error {{ color: red; font-weight: bold; }}
            .note {{ background-color: #fff3cd; border-left: 6px solid #ffecb5; padding: 12px; margin-top: 20px; }}
        </style>
        <script>
        function toggleChart() {{
            var box = document.getElementById('chartBox');
            box.style.display = (box.style.display === 'none') ? 'block' : 'none';
        }}
        window.addEventListener('DOMContentLoaded', function() {{
            document.querySelector('form').addEventListener('submit', function() {{
                const loading = document.createElement('p');
                loading.textContent = 'ğŸ”„ é æ¸¬ä¸­ï¼Œè«‹ç¨å€™...';
                loading.style.color = 'blue';
                this.appendChild(loading);
            }});
        }});
        </script>
    </head>
    <body>
        <h1>ğŸ“ˆ è‚¡ç¥¨é æ¸¬å„€è¡¨æ¿ï¼ˆFlask + å¤šæ—¥é æ¸¬ï¼‰</h1>

        <form method="POST">
            <label>è‚¡ç¥¨ä»£è™Ÿï¼š</label>
            <input type="text" name="ticker" required value="{request.form.get('ticker', '')}">
            <label>é æ¸¬å¤©æ•¸ï¼š</label>
            <input type="number" name="days" min="1" max="90" value="{request.form.get('days', 30)}">
            <label>æ¨¡å‹é¸æ“‡ï¼š</label>
            <select name="model">
                <option value="GradientBoosting" {'selected' if request.form.get('model') == 'GradientBoosting' else ''}>Gradient Boosting</option>
                <option value="RandomForest" {'selected' if request.form.get('model') == 'RandomForest' else ''}>Random Forest</option>
                <option value="LinearRegression" {'selected' if request.form.get('model') == 'LinearRegression' else ''}>Linear Regression</option>
                <option value="DecisionTree" {'selected' if request.form.get('model') == 'DecisionTree' else ''}>Decision Tree</option>
            </select>
            <button type="submit">é–‹å§‹é æ¸¬</button>
        </form>

        <div class="note">
            âš ï¸ <strong>æ³¨æ„ï¼š</strong>æœ¬ç¶²é ä½¿ç”¨ã€Œå¤šæ—¥é€£çºŒé æ¸¬ã€ï¼Œæ¯æ¬¡ä»¥å‰ä¸€æ—¥é æ¸¬çµæœä½œç‚ºä¸‹ä¸€å¤©çš„ä¾æ“šï¼Œå±¬æ–¼ multi-step forecastã€‚<br>
            çµ‚ç«¯æ©Ÿæ¨¡å¼å‰‡åƒ…é æ¸¬éš”æ—¥åƒ¹æ ¼ï¼ˆå–®æ—¥å–®æ­¥é æ¸¬ï¼‰ï¼Œå…©è€…é æ¸¬é‚è¼¯ä¸åŒï¼Œè«‹å‹¿ç›´æ¥æ¯”è¼ƒã€‚
        </div>

        <div class="error">{error_msg}</div>
        <hr>

        <button onclick="toggleChart()">ğŸ” é¡¯ç¤º / éš±è— é æ¸¬åœ–è¡¨</button>
        <div id="chartBox" style="display: block;">
            {{{{ chart_html | safe }}}}
        </div>

        <div>
            {{{{ summary_html | safe }}}}
        </div>
    </body>
    </html>
    """
    return render_template_string(html_template, chart_html=chart_html, summary_html=summary_html)
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=80)
